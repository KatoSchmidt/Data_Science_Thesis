[2025-04-18 13:57:25,697][the_well][INFO] - Run experiment turbulent_radiative_layer_2D-sinenet-SineNet-0.0002
[2025-04-18 13:57:25,697][the_well][INFO] - Run experiment turbulent_radiative_layer_2D-sinenet-SineNet-0.0002
[2025-04-18 13:57:25,700][the_well][INFO] - Configuration:
data:
  _target_: the_well.data.WellDataModule
  batch_size: 8
  well_base_path: /home/kschmidt/the_well/datasets/
  well_dataset_name: turbulent_radiative_layer_2D
  use_normalization: true
  min_dt_stride: 1
  max_dt_stride: 1
  n_steps_input: 4
  n_steps_output: 1
  include_filters:
  - turbulent_radiative_layer_tcool_0.03.hdf5
  normalization_type:
    _partial_: true
    _target_: the_well.data.normalization.ZScoreNormalization
  train_dataset:
    _partial_: true
    _target_: the_well.data.datasets.WellDataset
model:
  _target_: the_well.benchmark.models.sinenet.SineNet
  n_input_scalar_components: 2
  n_input_vector_components: 1
  n_output_scalar_components: 2
  n_output_vector_components: 1
  time_history: ${data.n_steps_input}
  time_future: ${data.n_steps_output}
  hidden_channels: 42
  padding_mode: circular
  activation: gelu
  num_layers: 4
  num_waves: 2
  num_blocks: 1
  norm: true
  mult: 1.2
lr_scheduler:
  _target_: the_well.benchmark.optim.schedulers.LinearWarmupCosineAnnealingLR
  warmup_epochs: 5
trainer:
  _target_: the_well.benchmark.trainer.Trainer
  epochs: 4
  val_frequency: 1
  rollout_val_frequency: 2
  short_validation_length: 4
  max_rollout_steps: 10
  num_time_intervals: 3
  make_rollout_videos: false
  checkpoint_frequency: 20
  loss_fn:
    _target_: the_well.benchmark.metrics.CustomMSELoss
  checkpoint_path: ''
  formatter: sinenet_formatter
experiment_dir: experiments/
auto_resume: false
folder_override: ''
checkpoint_override: ''
config_override: ''
validation_mode: false
wandb_project_name: the_well_sinenet_test
epochs: 4
val_frequency: 1
short_validation_length: 4
max_rollout_steps: 10
num_time_intervals: 3
data_workers: 0
optimizer:
  _target_: torch.optim.AdamW
  lr: 0.0002
_target_: the_well.benchmark.models.sinenet.SineNet
n_input_scalar_components: 2
n_input_vector_components: 1
n_output_scalar_components: 2
n_output_vector_components: 1
time_history: 4
time_future: 1
hidden_channels: 42
padding_mode: circular
activation: gelu
num_layers: 4
num_waves: 1
num_blocks: 1
norm: true
mult: 1.2
name: sinenet

[2025-04-18 13:57:25,700][the_well][INFO] - Configuration:
data:
  _target_: the_well.data.WellDataModule
  batch_size: 8
  well_base_path: /home/kschmidt/the_well/datasets/
  well_dataset_name: turbulent_radiative_layer_2D
  use_normalization: true
  min_dt_stride: 1
  max_dt_stride: 1
  n_steps_input: 4
  n_steps_output: 1
  include_filters:
  - turbulent_radiative_layer_tcool_0.03.hdf5
  normalization_type:
    _partial_: true
    _target_: the_well.data.normalization.ZScoreNormalization
  train_dataset:
    _partial_: true
    _target_: the_well.data.datasets.WellDataset
model:
  _target_: the_well.benchmark.models.sinenet.SineNet
  n_input_scalar_components: 2
  n_input_vector_components: 1
  n_output_scalar_components: 2
  n_output_vector_components: 1
  time_history: ${data.n_steps_input}
  time_future: ${data.n_steps_output}
  hidden_channels: 42
  padding_mode: circular
  activation: gelu
  num_layers: 4
  num_waves: 2
  num_blocks: 1
  norm: true
  mult: 1.2
lr_scheduler:
  _target_: the_well.benchmark.optim.schedulers.LinearWarmupCosineAnnealingLR
  warmup_epochs: 5
trainer:
  _target_: the_well.benchmark.trainer.Trainer
  epochs: 4
  val_frequency: 1
  rollout_val_frequency: 2
  short_validation_length: 4
  max_rollout_steps: 10
  num_time_intervals: 3
  make_rollout_videos: false
  checkpoint_frequency: 20
  loss_fn:
    _target_: the_well.benchmark.metrics.CustomMSELoss
  checkpoint_path: ''
  formatter: sinenet_formatter
experiment_dir: experiments/
auto_resume: false
folder_override: ''
checkpoint_override: ''
config_override: ''
validation_mode: false
wandb_project_name: the_well_sinenet_test
epochs: 4
val_frequency: 1
short_validation_length: 4
max_rollout_steps: 10
num_time_intervals: 3
data_workers: 0
optimizer:
  _target_: torch.optim.AdamW
  lr: 0.0002
_target_: the_well.benchmark.models.sinenet.SineNet
n_input_scalar_components: 2
n_input_vector_components: 1
n_output_scalar_components: 2
n_output_vector_components: 1
time_history: 4
time_future: 1
hidden_channels: 42
padding_mode: circular
activation: gelu
num_layers: 4
num_waves: 1
num_blocks: 1
norm: true
mult: 1.2
name: sinenet

[2025-04-18 13:57:26,869][the_well][INFO] - Distributed training: False
[2025-04-18 13:57:26,870][the_well][INFO] - Instantiate datamodule the_well.data.WellDataModule
[2025-04-18 13:57:26,983][the_well][INFO] - Instantiate model the_well.benchmark.models.sinenet.SineNet
circular
# par: 1616514, M=1.2
Channels: 42->50->60->72->87
===========================================================================
Layer (type:depth-idx)                             Param #
===========================================================================
SineNet                                            --
â”œâ”€GELU: 1-1                                        --
â”œâ”€Conv2d: 1-2                                      6,090
â”œâ”€ModuleList: 1-3                                  --
â”‚    â””â”€ModuleList: 2-1                             --
â”‚    â”‚    â””â”€Down: 3-1                              --
â”‚    â”‚    â”‚    â””â”€AvgPool2d: 4-1                    --
â”‚    â”‚    â”‚    â””â”€ModuleList: 4-2                   --
â”‚    â”‚    â”‚    â”‚    â””â”€ConvBlock: 5-1               41,700
â”‚    â”‚    â”‚    â””â”€Conv2d: 4-3                       2,150
â”‚    â”‚    â””â”€Down: 3-2                              --
â”‚    â”‚    â”‚    â””â”€AvgPool2d: 4-4                    --
â”‚    â”‚    â”‚    â””â”€ModuleList: 4-5                   --
â”‚    â”‚    â”‚    â”‚    â””â”€ConvBlock: 5-2               82,440
â”‚    â”‚    â”‚    â””â”€Conv2d: 4-6                       3,060
â”‚    â”‚    â””â”€Down: 3-3                              --
â”‚    â”‚    â”‚    â””â”€AvgPool2d: 4-7                    --
â”‚    â”‚    â”‚    â””â”€ModuleList: 4-8                   --
â”‚    â”‚    â”‚    â”‚    â””â”€ConvBlock: 5-3               113,184
â”‚    â”‚    â”‚    â””â”€Conv2d: 4-9                       4,392
â”‚    â”‚    â””â”€Down: 3-4                              --
â”‚    â”‚    â”‚    â””â”€AvgPool2d: 4-10                   --
â”‚    â”‚    â”‚    â””â”€ModuleList: 4-11                  --
â”‚    â”‚    â”‚    â”‚    â””â”€ConvBlock: 5-4               157,905
â”‚    â”‚    â”‚    â””â”€Conv2d: 4-12                      6,351
â”‚    â””â”€ModuleList: 2-2                             --
â”‚    â”‚    â””â”€Down: 3-5                              --
â”‚    â”‚    â”‚    â””â”€AvgPool2d: 4-13                   --
â”‚    â”‚    â”‚    â””â”€ModuleList: 4-14                  --
â”‚    â”‚    â”‚    â”‚    â””â”€ConvBlock: 5-5               41,700
â”‚    â”‚    â”‚    â””â”€Conv2d: 4-15                      2,150
â”‚    â”‚    â””â”€Down: 3-6                              --
â”‚    â”‚    â”‚    â””â”€AvgPool2d: 4-16                   --
â”‚    â”‚    â”‚    â””â”€ModuleList: 4-17                  --
â”‚    â”‚    â”‚    â”‚    â””â”€ConvBlock: 5-6               82,440
â”‚    â”‚    â”‚    â””â”€Conv2d: 4-18                      3,060
â”‚    â”‚    â””â”€Down: 3-7                              --
â”‚    â”‚    â”‚    â””â”€AvgPool2d: 4-19                   --
â”‚    â”‚    â”‚    â””â”€ModuleList: 4-20                  --
â”‚    â”‚    â”‚    â”‚    â””â”€ConvBlock: 5-7               113,184
â”‚    â”‚    â”‚    â””â”€Conv2d: 4-21                      4,392
â”‚    â”‚    â””â”€Down: 3-8                              --
â”‚    â”‚    â”‚    â””â”€AvgPool2d: 4-22                   --
â”‚    â”‚    â”‚    â””â”€ModuleList: 4-23                  --
â”‚    â”‚    â”‚    â”‚    â””â”€ConvBlock: 5-8               157,905
â”‚    â”‚    â”‚    â””â”€Conv2d: 4-24                      6,351
â”œâ”€ModuleList: 1-4                                  --
â”‚    â””â”€ModuleList: 2-3                             --
â”‚    â”‚    â””â”€Up: 3-9                                --
â”‚    â”‚    â”‚    â””â”€circular_interpolate: 4-25        --
â”‚    â”‚    â”‚    â””â”€ModuleList: 4-26                  --
â”‚    â”‚    â”‚    â”‚    â””â”€ConvBlock: 5-9               150,120
â”‚    â”‚    â”‚    â””â”€Conv2d: 4-27                      6,336
â”‚    â”‚    â””â”€Up: 3-10                               --
â”‚    â”‚    â”‚    â””â”€circular_interpolate: 4-28        --
â”‚    â”‚    â”‚    â””â”€ModuleList: 4-29                  --
â”‚    â”‚    â”‚    â”‚    â””â”€ConvBlock: 5-10              104,040
â”‚    â”‚    â”‚    â””â”€Conv2d: 4-30                      4,380
â”‚    â”‚    â””â”€Up: 3-11                               --
â”‚    â”‚    â”‚    â””â”€circular_interpolate: 4-31        --
â”‚    â”‚    â”‚    â””â”€ModuleList: 4-32                  --
â”‚    â”‚    â”‚    â”‚    â””â”€ConvBlock: 5-11              72,300
â”‚    â”‚    â”‚    â””â”€Conv2d: 4-33                      3,050
â”‚    â”‚    â””â”€Up: 3-12                               --
â”‚    â”‚    â”‚    â””â”€circular_interpolate: 4-34        --
â”‚    â”‚    â”‚    â””â”€ModuleList: 4-35                  --
â”‚    â”‚    â”‚    â”‚    â””â”€ConvBlock: 5-12              50,904
â”‚    â”‚    â”‚    â””â”€Conv2d: 4-36                      2,142
â”‚    â””â”€ModuleList: 2-4                             --
â”‚    â”‚    â””â”€Up: 3-13                               --
â”‚    â”‚    â”‚    â””â”€circular_interpolate: 4-37        --
â”‚    â”‚    â”‚    â””â”€ModuleList: 4-38                  --
â”‚    â”‚    â”‚    â”‚    â””â”€ConvBlock: 5-13              150,120
â”‚    â”‚    â”‚    â””â”€Conv2d: 4-39                      6,336
â”‚    â”‚    â””â”€Up: 3-14                               --
â”‚    â”‚    â”‚    â””â”€circular_interpolate: 4-40        --
â”‚    â”‚    â”‚    â””â”€ModuleList: 4-41                  --
â”‚    â”‚    â”‚    â”‚    â””â”€ConvBlock: 5-14              104,040
â”‚    â”‚    â”‚    â””â”€Conv2d: 4-42                      4,380
â”‚    â”‚    â””â”€Up: 3-15                               --
â”‚    â”‚    â”‚    â””â”€circular_interpolate: 4-43        --
â”‚    â”‚    â”‚    â””â”€ModuleList: 4-44                  --
â”‚    â”‚    â”‚    â”‚    â””â”€ConvBlock: 5-15              72,300
â”‚    â”‚    â”‚    â””â”€Conv2d: 4-45                      3,050
â”‚    â”‚    â””â”€Up: 3-16                               --
â”‚    â”‚    â”‚    â””â”€circular_interpolate: 4-46        --
â”‚    â”‚    â”‚    â””â”€ModuleList: 4-47                  --
â”‚    â”‚    â”‚    â”‚    â””â”€ConvBlock: 5-16              50,904
â”‚    â”‚    â”‚    â””â”€Conv2d: 4-48                      2,142
â”œâ”€Conv2d: 1-5                                      1,516
===========================================================================
Total params: 1,616,514
Trainable params: 1,616,514
Non-trainable params: 0
===========================================================================
[2025-04-18 13:57:29,065][the_well][INFO] - Instantiate optimizer torch.optim.AdamW
[2025-04-18 13:57:29,068][the_well][INFO] - Instantiate learning rate scheduler the_well.benchmark.optim.schedulers.LinearWarmupCosineAnnealingLR
[2025-04-18 13:57:29,076][the_well][INFO] - Final configuration:
data:
  _target_: the_well.data.WellDataModule
  batch_size: 8
  well_base_path: /home/kschmidt/the_well/datasets/
  well_dataset_name: turbulent_radiative_layer_2D
  use_normalization: true
  min_dt_stride: 1
  max_dt_stride: 1
  n_steps_input: 4
  n_steps_output: 1
  include_filters:
  - turbulent_radiative_layer_tcool_0.03.hdf5
  normalization_type:
    _partial_: true
    _target_: the_well.data.normalization.ZScoreNormalization
  train_dataset:
    _partial_: true
    _target_: the_well.data.datasets.WellDataset
model:
  _target_: the_well.benchmark.models.sinenet.SineNet
  n_input_scalar_components: 2
  n_input_vector_components: 1
  n_output_scalar_components: 2
  n_output_vector_components: 1
  time_history: ${data.n_steps_input}
  time_future: ${data.n_steps_output}
  hidden_channels: 42
  padding_mode: circular
  activation: gelu
  num_layers: 4
  num_waves: 2
  num_blocks: 1
  norm: true
  mult: 1.2
lr_scheduler:
  _target_: the_well.benchmark.optim.schedulers.LinearWarmupCosineAnnealingLR
  warmup_epochs: 5
trainer:
  _target_: the_well.benchmark.trainer.Trainer
  epochs: 4
  val_frequency: 1
  rollout_val_frequency: 2
  short_validation_length: 4
  max_rollout_steps: 10
  num_time_intervals: 3
  make_rollout_videos: false
  checkpoint_frequency: 20
  loss_fn:
    _target_: the_well.benchmark.metrics.CustomMSELoss
  checkpoint_path: ''
  formatter: sinenet_formatter
experiment_dir: experiments/
auto_resume: false
folder_override: ''
checkpoint_override: ''
config_override: ''
validation_mode: false
wandb_project_name: the_well_sinenet_test
epochs: 4
val_frequency: 1
short_validation_length: 4
max_rollout_steps: 10
num_time_intervals: 3
data_workers: 0
optimizer:
  _target_: torch.optim.AdamW
  lr: 0.0002
_target_: the_well.benchmark.models.sinenet.SineNet
n_input_scalar_components: 2
n_input_vector_components: 1
n_output_scalar_components: 2
n_output_vector_components: 1
time_history: 4
time_future: 1
hidden_channels: 42
padding_mode: circular
activation: gelu
num_layers: 4
num_waves: 1
num_blocks: 1
norm: true
mult: 1.2
name: sinenet

[2025-04-18 13:57:29,076][the_well][INFO] - Instantiate trainer the_well.benchmark.trainer.Trainer
[2025-04-18 13:57:29,082][the_well.benchmark.trainer.training][INFO] - Epoch 1/4: starting training
[2025-04-18 13:57:29,301][the_well][INFO] - Distributed training: False
[2025-04-18 13:57:29,301][the_well][INFO] - Instantiate datamodule the_well.data.WellDataModule
[2025-04-18 13:57:29,345][the_well][INFO] - Instantiate model the_well.benchmark.models.sinenet.SineNet
circular
# par: 1616514, M=1.2
Channels: 42->50->60->72->87
===========================================================================
Layer (type:depth-idx)                             Param #
===========================================================================
SineNet                                            --
â”œâ”€GELU: 1-1                                        --
â”œâ”€Conv2d: 1-2                                      6,090
â”œâ”€ModuleList: 1-3                                  --
â”‚    â””â”€ModuleList: 2-1                             --
â”‚    â”‚    â””â”€Down: 3-1                              --
â”‚    â”‚    â”‚    â””â”€AvgPool2d: 4-1                    --
â”‚    â”‚    â”‚    â””â”€ModuleList: 4-2                   --
â”‚    â”‚    â”‚    â”‚    â””â”€ConvBlock: 5-1               41,700
â”‚    â”‚    â”‚    â””â”€Conv2d: 4-3                       2,150
â”‚    â”‚    â””â”€Down: 3-2                              --
â”‚    â”‚    â”‚    â””â”€AvgPool2d: 4-4                    --
â”‚    â”‚    â”‚    â””â”€ModuleList: 4-5                   --
â”‚    â”‚    â”‚    â”‚    â””â”€ConvBlock: 5-2               82,440
â”‚    â”‚    â”‚    â””â”€Conv2d: 4-6                       3,060
â”‚    â”‚    â””â”€Down: 3-3                              --
â”‚    â”‚    â”‚    â””â”€AvgPool2d: 4-7                    --
â”‚    â”‚    â”‚    â””â”€ModuleList: 4-8                   --
â”‚    â”‚    â”‚    â”‚    â””â”€ConvBlock: 5-3               113,184
â”‚    â”‚    â”‚    â””â”€Conv2d: 4-9                       4,392
â”‚    â”‚    â””â”€Down: 3-4                              --
â”‚    â”‚    â”‚    â””â”€AvgPool2d: 4-10                   --
â”‚    â”‚    â”‚    â””â”€ModuleList: 4-11                  --
â”‚    â”‚    â”‚    â”‚    â””â”€ConvBlock: 5-4               157,905
â”‚    â”‚    â”‚    â””â”€Conv2d: 4-12                      6,351
â”‚    â””â”€ModuleList: 2-2                             --
â”‚    â”‚    â””â”€Down: 3-5                              --
â”‚    â”‚    â”‚    â””â”€AvgPool2d: 4-13                   --
â”‚    â”‚    â”‚    â””â”€ModuleList: 4-14                  --
â”‚    â”‚    â”‚    â”‚    â””â”€ConvBlock: 5-5               41,700
â”‚    â”‚    â”‚    â””â”€Conv2d: 4-15                      2,150
â”‚    â”‚    â””â”€Down: 3-6                              --
â”‚    â”‚    â”‚    â””â”€AvgPool2d: 4-16                   --
â”‚    â”‚    â”‚    â””â”€ModuleList: 4-17                  --
â”‚    â”‚    â”‚    â”‚    â””â”€ConvBlock: 5-6               82,440
â”‚    â”‚    â”‚    â””â”€Conv2d: 4-18                      3,060
â”‚    â”‚    â””â”€Down: 3-7                              --
â”‚    â”‚    â”‚    â””â”€AvgPool2d: 4-19                   --
â”‚    â”‚    â”‚    â””â”€ModuleList: 4-20                  --
â”‚    â”‚    â”‚    â”‚    â””â”€ConvBlock: 5-7               113,184
â”‚    â”‚    â”‚    â””â”€Conv2d: 4-21                      4,392
â”‚    â”‚    â””â”€Down: 3-8                              --
â”‚    â”‚    â”‚    â””â”€AvgPool2d: 4-22                   --
â”‚    â”‚    â”‚    â””â”€ModuleList: 4-23                  --
â”‚    â”‚    â”‚    â”‚    â””â”€ConvBlock: 5-8               157,905
â”‚    â”‚    â”‚    â””â”€Conv2d: 4-24                      6,351
â”œâ”€ModuleList: 1-4                                  --
â”‚    â””â”€ModuleList: 2-3                             --
â”‚    â”‚    â””â”€Up: 3-9                                --
â”‚    â”‚    â”‚    â””â”€circular_interpolate: 4-25        --
â”‚    â”‚    â”‚    â””â”€ModuleList: 4-26                  --
â”‚    â”‚    â”‚    â”‚    â””â”€ConvBlock: 5-9               150,120
â”‚    â”‚    â”‚    â””â”€Conv2d: 4-27                      6,336
â”‚    â”‚    â””â”€Up: 3-10                               --
â”‚    â”‚    â”‚    â””â”€circular_interpolate: 4-28        --
â”‚    â”‚    â”‚    â””â”€ModuleList: 4-29                  --
â”‚    â”‚    â”‚    â”‚    â””â”€ConvBlock: 5-10              104,040
â”‚    â”‚    â”‚    â””â”€Conv2d: 4-30                      4,380
â”‚    â”‚    â””â”€Up: 3-11                               --
â”‚    â”‚    â”‚    â””â”€circular_interpolate: 4-31        --
â”‚    â”‚    â”‚    â””â”€ModuleList: 4-32                  --
â”‚    â”‚    â”‚    â”‚    â””â”€ConvBlock: 5-11              72,300
â”‚    â”‚    â”‚    â””â”€Conv2d: 4-33                      3,050
â”‚    â”‚    â””â”€Up: 3-12                               --
â”‚    â”‚    â”‚    â””â”€circular_interpolate: 4-34        --
â”‚    â”‚    â”‚    â””â”€ModuleList: 4-35                  --
â”‚    â”‚    â”‚    â”‚    â””â”€ConvBlock: 5-12              50,904
â”‚    â”‚    â”‚    â””â”€Conv2d: 4-36                      2,142
â”‚    â””â”€ModuleList: 2-4                             --
â”‚    â”‚    â””â”€Up: 3-13                               --
â”‚    â”‚    â”‚    â””â”€circular_interpolate: 4-37        --
â”‚    â”‚    â”‚    â””â”€ModuleList: 4-38                  --
â”‚    â”‚    â”‚    â”‚    â””â”€ConvBlock: 5-13              150,120
â”‚    â”‚    â”‚    â””â”€Conv2d: 4-39                      6,336
â”‚    â”‚    â””â”€Up: 3-14                               --
â”‚    â”‚    â”‚    â””â”€circular_interpolate: 4-40        --
â”‚    â”‚    â”‚    â””â”€ModuleList: 4-41                  --
â”‚    â”‚    â”‚    â”‚    â””â”€ConvBlock: 5-14              104,040
â”‚    â”‚    â”‚    â””â”€Conv2d: 4-42                      4,380
â”‚    â”‚    â””â”€Up: 3-15                               --
â”‚    â”‚    â”‚    â””â”€circular_interpolate: 4-43        --
â”‚    â”‚    â”‚    â””â”€ModuleList: 4-44                  --
â”‚    â”‚    â”‚    â”‚    â””â”€ConvBlock: 5-15              72,300
â”‚    â”‚    â”‚    â””â”€Conv2d: 4-45                      3,050
â”‚    â”‚    â””â”€Up: 3-16                               --
â”‚    â”‚    â”‚    â””â”€circular_interpolate: 4-46        --
â”‚    â”‚    â”‚    â””â”€ModuleList: 4-47                  --
â”‚    â”‚    â”‚    â”‚    â””â”€ConvBlock: 5-16              50,904
â”‚    â”‚    â”‚    â””â”€Conv2d: 4-48                      2,142
â”œâ”€Conv2d: 1-5                                      1,516
===========================================================================
Total params: 1,616,514
Trainable params: 1,616,514
Non-trainable params: 0
===========================================================================
[2025-04-18 13:57:30,244][the_well][INFO] - Instantiate optimizer torch.optim.AdamW
[2025-04-18 13:57:30,246][the_well][INFO] - Instantiate learning rate scheduler the_well.benchmark.optim.schedulers.LinearWarmupCosineAnnealingLR
[2025-04-18 13:57:30,251][the_well][INFO] - Final configuration:
data:
  _target_: the_well.data.WellDataModule
  batch_size: 8
  well_base_path: /home/kschmidt/the_well/datasets/
  well_dataset_name: turbulent_radiative_layer_2D
  use_normalization: true
  min_dt_stride: 1
  max_dt_stride: 1
  n_steps_input: 4
  n_steps_output: 1
  include_filters:
  - turbulent_radiative_layer_tcool_0.03.hdf5
  normalization_type:
    _partial_: true
    _target_: the_well.data.normalization.ZScoreNormalization
  train_dataset:
    _partial_: true
    _target_: the_well.data.datasets.WellDataset
model:
  _target_: the_well.benchmark.models.sinenet.SineNet
  n_input_scalar_components: 2
  n_input_vector_components: 1
  n_output_scalar_components: 2
  n_output_vector_components: 1
  time_history: ${data.n_steps_input}
  time_future: ${data.n_steps_output}
  hidden_channels: 42
  padding_mode: circular
  activation: gelu
  num_layers: 4
  num_waves: 2
  num_blocks: 1
  norm: true
  mult: 1.2
lr_scheduler:
  _target_: the_well.benchmark.optim.schedulers.LinearWarmupCosineAnnealingLR
  warmup_epochs: 5
trainer:
  _target_: the_well.benchmark.trainer.Trainer
  epochs: 4
  val_frequency: 1
  rollout_val_frequency: 2
  short_validation_length: 4
  max_rollout_steps: 10
  num_time_intervals: 3
  make_rollout_videos: false
  checkpoint_frequency: 20
  loss_fn:
    _target_: the_well.benchmark.metrics.CustomMSELoss
  checkpoint_path: ''
  formatter: sinenet_formatter
experiment_dir: experiments/
auto_resume: false
folder_override: ''
checkpoint_override: ''
config_override: ''
validation_mode: false
wandb_project_name: the_well_sinenet_test
epochs: 4
val_frequency: 1
short_validation_length: 4
max_rollout_steps: 10
num_time_intervals: 3
data_workers: 0
optimizer:
  _target_: torch.optim.AdamW
  lr: 0.0002
_target_: the_well.benchmark.models.sinenet.SineNet
n_input_scalar_components: 2
n_input_vector_components: 1
n_output_scalar_components: 2
n_output_vector_components: 1
time_history: 4
time_future: 1
hidden_channels: 42
padding_mode: circular
activation: gelu
num_layers: 4
num_waves: 1
num_blocks: 1
norm: true
mult: 1.2
name: sinenet

[2025-04-18 13:57:30,251][the_well][INFO] - Instantiate trainer the_well.benchmark.trainer.Trainer
[2025-04-18 13:57:30,257][the_well.benchmark.trainer.training][INFO] - Epoch 1/4: starting training
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mturbulent_radiative_layer_2D-sinenet-SineNet-0.0002[0m at: [34mhttps://wandb.ai/kato-schmidt-university-of-amsterdam/the_well_sinenet_test/runs/ydt1ldbj[0m

JOB STATISTICS
==============
Job ID: 11261672
Cluster: snellius
User/Group: kschmidt/kschmidt
State: FAILED (exit code 143)
Nodes: 1
Cores per node: 16
CPU Utilized: 00:00:14
CPU Efficiency: 4.17% of 00:05:36 core-walltime
Job Wall-clock time: 00:00:21
Memory Utilized: 1.08 GB
Memory Efficiency: 0.60% of 180.00 GB (180.00 GB/node)
The task which had the largest memory consumption differs by 199.78% from the average task max memory consumption
