[2025-04-18 13:59:38,444][the_well][INFO] - Run experiment turbulent_radiative_layer_2D-sinenet-SineNet-0.0002
[2025-04-18 13:59:38,444][the_well][INFO] - Run experiment turbulent_radiative_layer_2D-sinenet-SineNet-0.0002
[2025-04-18 13:59:38,447][the_well][INFO] - Configuration:
data:
  _target_: the_well.data.WellDataModule
  batch_size: 8
  well_base_path: /home/kschmidt/the_well/datasets/
  well_dataset_name: turbulent_radiative_layer_2D
  use_normalization: true
  min_dt_stride: 1
  max_dt_stride: 1
  n_steps_input: 4
  n_steps_output: 1
  include_filters:
  - turbulent_radiative_layer_tcool_0.03.hdf5
  normalization_type:
    _partial_: true
    _target_: the_well.data.normalization.ZScoreNormalization
  train_dataset:
    _partial_: true
    _target_: the_well.data.datasets.WellDataset
model:
  _target_: the_well.benchmark.models.sinenet.SineNet
  n_input_scalar_components: 2
  n_input_vector_components: 1
  n_output_scalar_components: 2
  n_output_vector_components: 1
  time_history: ${data.n_steps_input}
  time_future: ${data.n_steps_output}
  hidden_channels: 42
  padding_mode: circular
  activation: gelu
  num_layers: 4
  num_waves: 2
  num_blocks: 1
  norm: true
  mult: 1.2
lr_scheduler:
  _target_: the_well.benchmark.optim.schedulers.LinearWarmupCosineAnnealingLR
  warmup_epochs: 5
trainer:
  _target_: the_well.benchmark.trainer.Trainer
  epochs: 4
  val_frequency: 1
  rollout_val_frequency: 2
  short_validation_length: 4
  max_rollout_steps: 10
  num_time_intervals: 3
  make_rollout_videos: false
  checkpoint_frequency: 20
  loss_fn:
    _target_: the_well.benchmark.metrics.CustomMSELoss
  checkpoint_path: ''
  formatter: sinenet_formatter
experiment_dir: experiments/
auto_resume: false
folder_override: ''
checkpoint_override: ''
config_override: ''
validation_mode: false
wandb_project_name: the_well_sinenet_test
epochs: 4
val_frequency: 1
short_validation_length: 4
max_rollout_steps: 10
num_time_intervals: 3
data_workers: 0
optimizer:
  _target_: torch.optim.AdamW
  lr: 0.0002
_target_: the_well.benchmark.models.sinenet.SineNet
n_input_scalar_components: 2
n_input_vector_components: 1
n_output_scalar_components: 2
n_output_vector_components: 1
time_history: 4
time_future: 1
hidden_channels: 42
padding_mode: circular
activation: gelu
num_layers: 4
num_waves: 1
num_blocks: 1
norm: true
mult: 1.2
name: sinenet

[2025-04-18 13:59:38,447][the_well][INFO] - Configuration:
data:
  _target_: the_well.data.WellDataModule
  batch_size: 8
  well_base_path: /home/kschmidt/the_well/datasets/
  well_dataset_name: turbulent_radiative_layer_2D
  use_normalization: true
  min_dt_stride: 1
  max_dt_stride: 1
  n_steps_input: 4
  n_steps_output: 1
  include_filters:
  - turbulent_radiative_layer_tcool_0.03.hdf5
  normalization_type:
    _partial_: true
    _target_: the_well.data.normalization.ZScoreNormalization
  train_dataset:
    _partial_: true
    _target_: the_well.data.datasets.WellDataset
model:
  _target_: the_well.benchmark.models.sinenet.SineNet
  n_input_scalar_components: 2
  n_input_vector_components: 1
  n_output_scalar_components: 2
  n_output_vector_components: 1
  time_history: ${data.n_steps_input}
  time_future: ${data.n_steps_output}
  hidden_channels: 42
  padding_mode: circular
  activation: gelu
  num_layers: 4
  num_waves: 2
  num_blocks: 1
  norm: true
  mult: 1.2
lr_scheduler:
  _target_: the_well.benchmark.optim.schedulers.LinearWarmupCosineAnnealingLR
  warmup_epochs: 5
trainer:
  _target_: the_well.benchmark.trainer.Trainer
  epochs: 4
  val_frequency: 1
  rollout_val_frequency: 2
  short_validation_length: 4
  max_rollout_steps: 10
  num_time_intervals: 3
  make_rollout_videos: false
  checkpoint_frequency: 20
  loss_fn:
    _target_: the_well.benchmark.metrics.CustomMSELoss
  checkpoint_path: ''
  formatter: sinenet_formatter
experiment_dir: experiments/
auto_resume: false
folder_override: ''
checkpoint_override: ''
config_override: ''
validation_mode: false
wandb_project_name: the_well_sinenet_test
epochs: 4
val_frequency: 1
short_validation_length: 4
max_rollout_steps: 10
num_time_intervals: 3
data_workers: 0
optimizer:
  _target_: torch.optim.AdamW
  lr: 0.0002
_target_: the_well.benchmark.models.sinenet.SineNet
n_input_scalar_components: 2
n_input_vector_components: 1
n_output_scalar_components: 2
n_output_vector_components: 1
time_history: 4
time_future: 1
hidden_channels: 42
padding_mode: circular
activation: gelu
num_layers: 4
num_waves: 1
num_blocks: 1
norm: true
mult: 1.2
name: sinenet

[2025-04-18 13:59:39,743][the_well][INFO] - Distributed training: False
[2025-04-18 13:59:39,743][the_well][INFO] - Instantiate datamodule the_well.data.WellDataModule
[2025-04-18 13:59:39,853][the_well][INFO] - Instantiate model the_well.benchmark.models.sinenet.SineNet
circular
# par: 1616514, M=1.2
Channels: 42->50->60->72->87
===========================================================================
Layer (type:depth-idx)                             Param #
===========================================================================
SineNet                                            --
├─GELU: 1-1                                        --
├─Conv2d: 1-2                                      6,090
├─ModuleList: 1-3                                  --
│    └─ModuleList: 2-1                             --
│    │    └─Down: 3-1                              --
│    │    │    └─AvgPool2d: 4-1                    --
│    │    │    └─ModuleList: 4-2                   --
│    │    │    │    └─ConvBlock: 5-1               41,700
│    │    │    └─Conv2d: 4-3                       2,150
│    │    └─Down: 3-2                              --
│    │    │    └─AvgPool2d: 4-4                    --
│    │    │    └─ModuleList: 4-5                   --
│    │    │    │    └─ConvBlock: 5-2               82,440
│    │    │    └─Conv2d: 4-6                       3,060
│    │    └─Down: 3-3                              --
│    │    │    └─AvgPool2d: 4-7                    --
│    │    │    └─ModuleList: 4-8                   --
│    │    │    │    └─ConvBlock: 5-3               113,184
│    │    │    └─Conv2d: 4-9                       4,392
│    │    └─Down: 3-4                              --
│    │    │    └─AvgPool2d: 4-10                   --
│    │    │    └─ModuleList: 4-11                  --
│    │    │    │    └─ConvBlock: 5-4               157,905
│    │    │    └─Conv2d: 4-12                      6,351
│    └─ModuleList: 2-2                             --
│    │    └─Down: 3-5                              --
│    │    │    └─AvgPool2d: 4-13                   --
│    │    │    └─ModuleList: 4-14                  --
│    │    │    │    └─ConvBlock: 5-5               41,700
│    │    │    └─Conv2d: 4-15                      2,150
│    │    └─Down: 3-6                              --
│    │    │    └─AvgPool2d: 4-16                   --
│    │    │    └─ModuleList: 4-17                  --
│    │    │    │    └─ConvBlock: 5-6               82,440
│    │    │    └─Conv2d: 4-18                      3,060
│    │    └─Down: 3-7                              --
│    │    │    └─AvgPool2d: 4-19                   --
│    │    │    └─ModuleList: 4-20                  --
│    │    │    │    └─ConvBlock: 5-7               113,184
│    │    │    └─Conv2d: 4-21                      4,392
│    │    └─Down: 3-8                              --
│    │    │    └─AvgPool2d: 4-22                   --
│    │    │    └─ModuleList: 4-23                  --
│    │    │    │    └─ConvBlock: 5-8               157,905
│    │    │    └─Conv2d: 4-24                      6,351
├─ModuleList: 1-4                                  --
│    └─ModuleList: 2-3                             --
│    │    └─Up: 3-9                                --
│    │    │    └─circular_interpolate: 4-25        --
│    │    │    └─ModuleList: 4-26                  --
│    │    │    │    └─ConvBlock: 5-9               150,120
│    │    │    └─Conv2d: 4-27                      6,336
│    │    └─Up: 3-10                               --
│    │    │    └─circular_interpolate: 4-28        --
│    │    │    └─ModuleList: 4-29                  --
│    │    │    │    └─ConvBlock: 5-10              104,040
│    │    │    └─Conv2d: 4-30                      4,380
│    │    └─Up: 3-11                               --
│    │    │    └─circular_interpolate: 4-31        --
│    │    │    └─ModuleList: 4-32                  --
│    │    │    │    └─ConvBlock: 5-11              72,300
│    │    │    └─Conv2d: 4-33                      3,050
│    │    └─Up: 3-12                               --
│    │    │    └─circular_interpolate: 4-34        --
│    │    │    └─ModuleList: 4-35                  --
│    │    │    │    └─ConvBlock: 5-12              50,904
│    │    │    └─Conv2d: 4-36                      2,142
│    └─ModuleList: 2-4                             --
│    │    └─Up: 3-13                               --
│    │    │    └─circular_interpolate: 4-37        --
│    │    │    └─ModuleList: 4-38                  --
│    │    │    │    └─ConvBlock: 5-13              150,120
│    │    │    └─Conv2d: 4-39                      6,336
│    │    └─Up: 3-14                               --
│    │    │    └─circular_interpolate: 4-40        --
│    │    │    └─ModuleList: 4-41                  --
│    │    │    │    └─ConvBlock: 5-14              104,040
│    │    │    └─Conv2d: 4-42                      4,380
│    │    └─Up: 3-15                               --
│    │    │    └─circular_interpolate: 4-43        --
│    │    │    └─ModuleList: 4-44                  --
│    │    │    │    └─ConvBlock: 5-15              72,300
│    │    │    └─Conv2d: 4-45                      3,050
│    │    └─Up: 3-16                               --
│    │    │    └─circular_interpolate: 4-46        --
│    │    │    └─ModuleList: 4-47                  --
│    │    │    │    └─ConvBlock: 5-16              50,904
│    │    │    └─Conv2d: 4-48                      2,142
├─Conv2d: 1-5                                      1,516
===========================================================================
Total params: 1,616,514
Trainable params: 1,616,514
Non-trainable params: 0
===========================================================================
[2025-04-18 13:59:41,840][the_well][INFO] - Instantiate optimizer torch.optim.AdamW
[2025-04-18 13:59:41,843][the_well][INFO] - Instantiate learning rate scheduler the_well.benchmark.optim.schedulers.LinearWarmupCosineAnnealingLR
[2025-04-18 13:59:41,850][the_well][INFO] - Final configuration:
data:
  _target_: the_well.data.WellDataModule
  batch_size: 8
  well_base_path: /home/kschmidt/the_well/datasets/
  well_dataset_name: turbulent_radiative_layer_2D
  use_normalization: true
  min_dt_stride: 1
  max_dt_stride: 1
  n_steps_input: 4
  n_steps_output: 1
  include_filters:
  - turbulent_radiative_layer_tcool_0.03.hdf5
  normalization_type:
    _partial_: true
    _target_: the_well.data.normalization.ZScoreNormalization
  train_dataset:
    _partial_: true
    _target_: the_well.data.datasets.WellDataset
model:
  _target_: the_well.benchmark.models.sinenet.SineNet
  n_input_scalar_components: 2
  n_input_vector_components: 1
  n_output_scalar_components: 2
  n_output_vector_components: 1
  time_history: ${data.n_steps_input}
  time_future: ${data.n_steps_output}
  hidden_channels: 42
  padding_mode: circular
  activation: gelu
  num_layers: 4
  num_waves: 2
  num_blocks: 1
  norm: true
  mult: 1.2
lr_scheduler:
  _target_: the_well.benchmark.optim.schedulers.LinearWarmupCosineAnnealingLR
  warmup_epochs: 5
trainer:
  _target_: the_well.benchmark.trainer.Trainer
  epochs: 4
  val_frequency: 1
  rollout_val_frequency: 2
  short_validation_length: 4
  max_rollout_steps: 10
  num_time_intervals: 3
  make_rollout_videos: false
  checkpoint_frequency: 20
  loss_fn:
    _target_: the_well.benchmark.metrics.CustomMSELoss
  checkpoint_path: ''
  formatter: sinenet_formatter
experiment_dir: experiments/
auto_resume: false
folder_override: ''
checkpoint_override: ''
config_override: ''
validation_mode: false
wandb_project_name: the_well_sinenet_test
epochs: 4
val_frequency: 1
short_validation_length: 4
max_rollout_steps: 10
num_time_intervals: 3
data_workers: 0
optimizer:
  _target_: torch.optim.AdamW
  lr: 0.0002
_target_: the_well.benchmark.models.sinenet.SineNet
n_input_scalar_components: 2
n_input_vector_components: 1
n_output_scalar_components: 2
n_output_vector_components: 1
time_history: 4
time_future: 1
hidden_channels: 42
padding_mode: circular
activation: gelu
num_layers: 4
num_waves: 1
num_blocks: 1
norm: true
mult: 1.2
name: sinenet

[2025-04-18 13:59:41,850][the_well][INFO] - Instantiate trainer the_well.benchmark.trainer.Trainer
[2025-04-18 13:59:41,856][the_well.benchmark.trainer.training][INFO] - Epoch 1/4: starting training
[2025-04-18 13:59:42,038][the_well][INFO] - Distributed training: False
[2025-04-18 13:59:42,038][the_well][INFO] - Instantiate datamodule the_well.data.WellDataModule
[2025-04-18 13:59:42,082][the_well][INFO] - Instantiate model the_well.benchmark.models.sinenet.SineNet
circular
# par: 1616514, M=1.2
Channels: 42->50->60->72->87
===========================================================================
Layer (type:depth-idx)                             Param #
===========================================================================
SineNet                                            --
├─GELU: 1-1                                        --
├─Conv2d: 1-2                                      6,090
├─ModuleList: 1-3                                  --
│    └─ModuleList: 2-1                             --
│    │    └─Down: 3-1                              --
│    │    │    └─AvgPool2d: 4-1                    --
│    │    │    └─ModuleList: 4-2                   --
│    │    │    │    └─ConvBlock: 5-1               41,700
│    │    │    └─Conv2d: 4-3                       2,150
│    │    └─Down: 3-2                              --
│    │    │    └─AvgPool2d: 4-4                    --
│    │    │    └─ModuleList: 4-5                   --
│    │    │    │    └─ConvBlock: 5-2               82,440
│    │    │    └─Conv2d: 4-6                       3,060
│    │    └─Down: 3-3                              --
│    │    │    └─AvgPool2d: 4-7                    --
│    │    │    └─ModuleList: 4-8                   --
│    │    │    │    └─ConvBlock: 5-3               113,184
│    │    │    └─Conv2d: 4-9                       4,392
│    │    └─Down: 3-4                              --
│    │    │    └─AvgPool2d: 4-10                   --
│    │    │    └─ModuleList: 4-11                  --
│    │    │    │    └─ConvBlock: 5-4               157,905
│    │    │    └─Conv2d: 4-12                      6,351
│    └─ModuleList: 2-2                             --
│    │    └─Down: 3-5                              --
│    │    │    └─AvgPool2d: 4-13                   --
│    │    │    └─ModuleList: 4-14                  --
│    │    │    │    └─ConvBlock: 5-5               41,700
│    │    │    └─Conv2d: 4-15                      2,150
│    │    └─Down: 3-6                              --
│    │    │    └─AvgPool2d: 4-16                   --
│    │    │    └─ModuleList: 4-17                  --
│    │    │    │    └─ConvBlock: 5-6               82,440
│    │    │    └─Conv2d: 4-18                      3,060
│    │    └─Down: 3-7                              --
│    │    │    └─AvgPool2d: 4-19                   --
│    │    │    └─ModuleList: 4-20                  --
│    │    │    │    └─ConvBlock: 5-7               113,184
│    │    │    └─Conv2d: 4-21                      4,392
│    │    └─Down: 3-8                              --
│    │    │    └─AvgPool2d: 4-22                   --
│    │    │    └─ModuleList: 4-23                  --
│    │    │    │    └─ConvBlock: 5-8               157,905
│    │    │    └─Conv2d: 4-24                      6,351
├─ModuleList: 1-4                                  --
│    └─ModuleList: 2-3                             --
│    │    └─Up: 3-9                                --
│    │    │    └─circular_interpolate: 4-25        --
│    │    │    └─ModuleList: 4-26                  --
│    │    │    │    └─ConvBlock: 5-9               150,120
│    │    │    └─Conv2d: 4-27                      6,336
│    │    └─Up: 3-10                               --
│    │    │    └─circular_interpolate: 4-28        --
│    │    │    └─ModuleList: 4-29                  --
│    │    │    │    └─ConvBlock: 5-10              104,040
│    │    │    └─Conv2d: 4-30                      4,380
│    │    └─Up: 3-11                               --
│    │    │    └─circular_interpolate: 4-31        --
│    │    │    └─ModuleList: 4-32                  --
│    │    │    │    └─ConvBlock: 5-11              72,300
│    │    │    └─Conv2d: 4-33                      3,050
│    │    └─Up: 3-12                               --
│    │    │    └─circular_interpolate: 4-34        --
│    │    │    └─ModuleList: 4-35                  --
│    │    │    │    └─ConvBlock: 5-12              50,904
│    │    │    └─Conv2d: 4-36                      2,142
│    └─ModuleList: 2-4                             --
│    │    └─Up: 3-13                               --
│    │    │    └─circular_interpolate: 4-37        --
│    │    │    └─ModuleList: 4-38                  --
│    │    │    │    └─ConvBlock: 5-13              150,120
│    │    │    └─Conv2d: 4-39                      6,336
│    │    └─Up: 3-14                               --
│    │    │    └─circular_interpolate: 4-40        --
│    │    │    └─ModuleList: 4-41                  --
│    │    │    │    └─ConvBlock: 5-14              104,040
│    │    │    └─Conv2d: 4-42                      4,380
│    │    └─Up: 3-15                               --
│    │    │    └─circular_interpolate: 4-43        --
│    │    │    └─ModuleList: 4-44                  --
│    │    │    │    └─ConvBlock: 5-15              72,300
│    │    │    └─Conv2d: 4-45                      3,050
│    │    └─Up: 3-16                               --
│    │    │    └─circular_interpolate: 4-46        --
│    │    │    └─ModuleList: 4-47                  --
│    │    │    │    └─ConvBlock: 5-16              50,904
│    │    │    └─Conv2d: 4-48                      2,142
├─Conv2d: 1-5                                      1,516
===========================================================================
Total params: 1,616,514
Trainable params: 1,616,514
Non-trainable params: 0
===========================================================================
[2025-04-18 13:59:43,072][the_well][INFO] - Instantiate optimizer torch.optim.AdamW
[2025-04-18 13:59:43,074][the_well][INFO] - Instantiate learning rate scheduler the_well.benchmark.optim.schedulers.LinearWarmupCosineAnnealingLR
[2025-04-18 13:59:43,079][the_well][INFO] - Final configuration:
data:
  _target_: the_well.data.WellDataModule
  batch_size: 8
  well_base_path: /home/kschmidt/the_well/datasets/
  well_dataset_name: turbulent_radiative_layer_2D
  use_normalization: true
  min_dt_stride: 1
  max_dt_stride: 1
  n_steps_input: 4
  n_steps_output: 1
  include_filters:
  - turbulent_radiative_layer_tcool_0.03.hdf5
  normalization_type:
    _partial_: true
    _target_: the_well.data.normalization.ZScoreNormalization
  train_dataset:
    _partial_: true
    _target_: the_well.data.datasets.WellDataset
model:
  _target_: the_well.benchmark.models.sinenet.SineNet
  n_input_scalar_components: 2
  n_input_vector_components: 1
  n_output_scalar_components: 2
  n_output_vector_components: 1
  time_history: ${data.n_steps_input}
  time_future: ${data.n_steps_output}
  hidden_channels: 42
  padding_mode: circular
  activation: gelu
  num_layers: 4
  num_waves: 2
  num_blocks: 1
  norm: true
  mult: 1.2
lr_scheduler:
  _target_: the_well.benchmark.optim.schedulers.LinearWarmupCosineAnnealingLR
  warmup_epochs: 5
trainer:
  _target_: the_well.benchmark.trainer.Trainer
  epochs: 4
  val_frequency: 1
  rollout_val_frequency: 2
  short_validation_length: 4
  max_rollout_steps: 10
  num_time_intervals: 3
  make_rollout_videos: false
  checkpoint_frequency: 20
  loss_fn:
    _target_: the_well.benchmark.metrics.CustomMSELoss
  checkpoint_path: ''
  formatter: sinenet_formatter
experiment_dir: experiments/
auto_resume: false
folder_override: ''
checkpoint_override: ''
config_override: ''
validation_mode: false
wandb_project_name: the_well_sinenet_test
epochs: 4
val_frequency: 1
short_validation_length: 4
max_rollout_steps: 10
num_time_intervals: 3
data_workers: 0
optimizer:
  _target_: torch.optim.AdamW
  lr: 0.0002
_target_: the_well.benchmark.models.sinenet.SineNet
n_input_scalar_components: 2
n_input_vector_components: 1
n_output_scalar_components: 2
n_output_vector_components: 1
time_history: 4
time_future: 1
hidden_channels: 42
padding_mode: circular
activation: gelu
num_layers: 4
num_waves: 1
num_blocks: 1
norm: true
mult: 1.2
name: sinenet

[2025-04-18 13:59:43,079][the_well][INFO] - Instantiate trainer the_well.benchmark.trainer.Trainer
[2025-04-18 13:59:43,085][the_well.benchmark.trainer.training][INFO] - Epoch 1/4: starting training
[2025-04-18 13:59:43,449][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 1/97: loss 12.289007186889648, total_time 1.5921220779418945, batch time 0.14856529235839844, forward time 0.6411094665527344, backward time 0.8024463653564453
[2025-04-18 13:59:43,634][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 2/97: loss 12.565325736999512, total_time 0.18464040756225586, batch time 0.1019287109375, forward time 0.02961564064025879, backward time 0.053095102310180664
[2025-04-18 13:59:43,805][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 3/97: loss 6.723997116088867, total_time 0.17115497589111328, batch time 0.0759427547454834, forward time 0.03811287879943848, backward time 0.0570981502532959
[2025-04-18 13:59:43,979][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 4/97: loss 4.844141960144043, total_time 0.17289376258850098, batch time 0.08466935157775879, forward time 0.02953481674194336, backward time 0.05868840217590332
[2025-04-18 13:59:44,160][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 5/97: loss 6.07877254486084, total_time 0.1812911033630371, batch time 0.0694432258605957, forward time 0.036530494689941406, backward time 0.0753166675567627
[2025-04-18 13:59:44,301][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 6/97: loss 4.217991828918457, total_time 0.1405322551727295, batch time 0.05572390556335449, forward time 0.03129243850708008, backward time 0.053514719009399414
[2025-04-18 13:59:44,442][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 7/97: loss 4.738706588745117, total_time 0.13991522789001465, batch time 0.05681872367858887, forward time 0.02907848358154297, backward time 0.05401730537414551
[2025-04-18 13:59:44,579][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 8/97: loss 3.581002950668335, total_time 0.13715791702270508, batch time 0.05518674850463867, forward time 0.028365612030029297, backward time 0.053604841232299805
[2025-04-18 13:59:44,731][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 9/97: loss 8.36885929107666, total_time 0.15074801445007324, batch time 0.06261253356933594, forward time 0.03143429756164551, backward time 0.05669999122619629
[2025-04-18 13:59:44,739][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 1/97: loss 16.295291900634766, total_time 1.653686761856079, batch time 0.13215327262878418, forward time 0.5701179504394531, backward time 0.9514148235321045
[2025-04-18 13:59:44,924][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 10/97: loss 4.437358856201172, total_time 0.19341325759887695, batch time 0.0571589469909668, forward time 0.03823065757751465, backward time 0.0980224609375
[2025-04-18 13:59:44,937][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 2/97: loss 15.725217819213867, total_time 0.1972339153289795, batch time 0.06063055992126465, forward time 0.05030369758605957, backward time 0.08629870414733887
[2025-04-18 13:59:45,112][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 11/97: loss 4.5204949378967285, total_time 0.18754982948303223, batch time 0.04654431343078613, forward time 0.042534589767456055, backward time 0.09846997261047363
[2025-04-18 13:59:45,121][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 3/97: loss 11.431804656982422, total_time 0.18332600593566895, batch time 0.04279899597167969, forward time 0.04945540428161621, backward time 0.09107065200805664
[2025-04-18 13:59:45,269][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 12/97: loss 4.373448371887207, total_time 0.1556558609008789, batch time 0.03608441352844238, forward time 0.024832725524902344, backward time 0.09473800659179688
[2025-04-18 13:59:45,295][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 4/97: loss 9.905258178710938, total_time 0.17412304878234863, batch time 0.05482625961303711, forward time 0.050718069076538086, backward time 0.06857776641845703
[2025-04-18 13:59:45,427][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 13/97: loss 4.086982727050781, total_time 0.158250093460083, batch time 0.04077935218811035, forward time 0.025331974029541016, backward time 0.09213733673095703
[2025-04-18 13:59:45,456][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 5/97: loss 15.393640518188477, total_time 0.16031503677368164, batch time 0.044860124588012695, forward time 0.04948544502258301, backward time 0.06596875190734863
[2025-04-18 13:59:45,597][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 14/97: loss 2.8739991188049316, total_time 0.1680004596710205, batch time 0.04434847831726074, forward time 0.025018692016601562, backward time 0.0986323356628418
[2025-04-18 13:59:45,619][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 6/97: loss 7.153034210205078, total_time 0.16303205490112305, batch time 0.039545536041259766, forward time 0.04986405372619629, backward time 0.07362198829650879
[2025-04-18 13:59:45,758][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 15/97: loss 2.5102221965789795, total_time 0.1604142189025879, batch time 0.037630558013916016, forward time 0.025428056716918945, backward time 0.09735441207885742
[2025-04-18 13:59:45,782][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 7/97: loss 6.768385887145996, total_time 0.16253924369812012, batch time 0.04016399383544922, forward time 0.051088571548461914, backward time 0.07128596305847168
[2025-04-18 13:59:45,926][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 16/97: loss 4.103589057922363, total_time 0.16742396354675293, batch time 0.04202747344970703, forward time 0.027328968048095703, backward time 0.09806632995605469
[2025-04-18 13:59:45,946][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 8/97: loss 5.989645481109619, total_time 0.16329288482666016, batch time 0.03851604461669922, forward time 0.04883217811584473, backward time 0.0759439468383789
[2025-04-18 13:59:46,085][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 17/97: loss 1.718019962310791, total_time 0.15875697135925293, batch time 0.03690791130065918, forward time 0.024724483489990234, backward time 0.0971231460571289
[2025-04-18 13:59:46,110][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 9/97: loss 8.894621849060059, total_time 0.16300511360168457, batch time 0.04112410545349121, forward time 0.050582170486450195, backward time 0.07129836082458496
[2025-04-18 13:59:46,243][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 18/97: loss 5.238026142120361, total_time 0.15784168243408203, batch time 0.03603029251098633, forward time 0.024779796600341797, backward time 0.0970308780670166
[2025-04-18 13:59:46,268][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 10/97: loss 7.046321392059326, total_time 0.15775084495544434, batch time 0.03598427772521973, forward time 0.050699472427368164, backward time 0.07106661796569824
[2025-04-18 13:59:46,407][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 19/97: loss 3.3050575256347656, total_time 0.16300392150878906, batch time 0.039276838302612305, forward time 0.0262911319732666, backward time 0.09743475914001465
[2025-04-18 13:59:46,429][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 11/97: loss 2.7533326148986816, total_time 0.16095972061157227, batch time 0.03644871711730957, forward time 0.05093741416931152, backward time 0.07357311248779297
[2025-04-18 13:59:46,569][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 20/97: loss 1.6691441535949707, total_time 0.16174697875976562, batch time 0.03575325012207031, forward time 0.027941226959228516, backward time 0.09805130958557129
[2025-04-18 13:59:46,589][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 12/97: loss 4.036313056945801, total_time 0.15966176986694336, batch time 0.03562211990356445, forward time 0.04815340042114258, backward time 0.07588529586791992
[2025-04-18 13:59:46,738][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 21/97: loss 2.7991790771484375, total_time 0.16904735565185547, batch time 0.03801560401916504, forward time 0.03285551071166992, backward time 0.0981755256652832
[2025-04-18 13:59:46,755][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 13/97: loss 2.1605167388916016, total_time 0.16492486000061035, batch time 0.034806013107299805, forward time 0.04929351806640625, backward time 0.08082413673400879
[2025-04-18 13:59:46,901][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 22/97: loss 2.7103099822998047, total_time 0.16265130043029785, batch time 0.03485989570617676, forward time 0.02974867820739746, backward time 0.09804153442382812
[2025-04-18 13:59:46,920][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 14/97: loss 4.061448097229004, total_time 0.16480255126953125, batch time 0.03755474090576172, forward time 0.04884958267211914, backward time 0.07839703559875488
[2025-04-18 13:59:47,065][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 23/97: loss 2.407573699951172, total_time 0.16311335563659668, batch time 0.03487801551818848, forward time 0.029667377471923828, backward time 0.09856748580932617
[2025-04-18 13:59:47,083][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 15/97: loss 3.676377773284912, total_time 0.163191556930542, batch time 0.03489542007446289, forward time 0.049495697021484375, backward time 0.07879972457885742
[2025-04-18 13:59:47,238][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 24/97: loss 4.327573776245117, total_time 0.17122411727905273, batch time 0.037137508392333984, forward time 0.03566741943359375, backward time 0.0984184741973877
[2025-04-18 13:59:47,252][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 16/97: loss 3.95951509475708, total_time 0.16812491416931152, batch time 0.03515219688415527, forward time 0.049263954162597656, backward time 0.08370804786682129
[2025-04-18 13:59:47,411][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 25/97: loss 3.4321818351745605, total_time 0.17285633087158203, batch time 0.03665900230407715, forward time 0.03789114952087402, backward time 0.09830546379089355
[2025-04-18 13:59:47,423][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 17/97: loss 6.888473987579346, total_time 0.1707472801208496, batch time 0.03527951240539551, forward time 0.049524545669555664, backward time 0.08594226837158203
[2025-04-18 13:59:47,580][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 26/97: loss 1.9979275465011597, total_time 0.16854143142700195, batch time 0.0352482795715332, forward time 0.035012245178222656, backward time 0.09827971458435059
[2025-04-18 13:59:47,594][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 18/97: loss 2.0547282695770264, total_time 0.16959881782531738, batch time 0.037442922592163086, forward time 0.04878973960876465, backward time 0.08336496353149414
[2025-04-18 13:59:47,748][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 27/97: loss 2.4200594425201416, total_time 0.1679987907409668, batch time 0.034837961196899414, forward time 0.03490042686462402, backward time 0.09825968742370605
[2025-04-18 13:59:47,763][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 19/97: loss 3.43876576423645, total_time 0.1681501865386963, batch time 0.03483891487121582, forward time 0.049762725830078125, backward time 0.08354759216308594
[2025-04-18 13:59:47,920][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 28/97: loss 2.2016499042510986, total_time 0.171187162399292, batch time 0.03526663780212402, forward time 0.037515878677368164, backward time 0.0984039306640625
[2025-04-18 13:59:47,932][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 20/97: loss 1.779171347618103, total_time 0.16905760765075684, batch time 0.03507590293884277, forward time 0.04793834686279297, backward time 0.08604240417480469
[2025-04-18 13:59:48,094][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 29/97: loss 2.9072327613830566, total_time 0.17304372787475586, batch time 0.03510642051696777, forward time 0.039664506912231445, backward time 0.09827208518981934
[2025-04-18 13:59:48,104][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 21/97: loss 3.754377841949463, total_time 0.17102742195129395, batch time 0.03471565246582031, forward time 0.0478365421295166, backward time 0.08847427368164062
[2025-04-18 13:59:48,267][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 30/97: loss 2.735623836517334, total_time 0.17338013648986816, batch time 0.0350041389465332, forward time 0.03990340232849121, backward time 0.09847187995910645
[2025-04-18 13:59:48,278][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 22/97: loss 4.20288610458374, total_time 0.17358875274658203, batch time 0.035039663314819336, forward time 0.04971742630004883, backward time 0.08883118629455566
[2025-04-18 13:59:48,440][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 31/97: loss 2.905900001525879, total_time 0.17245244979858398, batch time 0.03468728065490723, forward time 0.03996109962463379, backward time 0.09780263900756836
[2025-04-18 13:59:48,450][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 23/97: loss 1.829987645149231, total_time 0.17212319374084473, batch time 0.03507113456726074, forward time 0.049288272857666016, backward time 0.08776283264160156
[2025-04-18 13:59:48,617][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 32/97: loss 2.6021361351013184, total_time 0.17618036270141602, batch time 0.03528022766113281, forward time 0.04250001907348633, backward time 0.09839916229248047
[2025-04-18 13:59:48,625][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 24/97: loss 7.324563980102539, total_time 0.17415928840637207, batch time 0.03493452072143555, forward time 0.048338890075683594, backward time 0.09088492393493652
[2025-04-18 13:59:48,793][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 33/97: loss 1.9066098928451538, total_time 0.17518258094787598, batch time 0.034676551818847656, forward time 0.04207730293273926, backward time 0.09842753410339355
[2025-04-18 13:59:48,801][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 25/97: loss 7.778191089630127, total_time 0.17526578903198242, batch time 0.03506612777709961, forward time 0.04921150207519531, backward time 0.0909874439239502
[2025-04-18 13:59:48,973][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 34/97: loss 1.836261510848999, total_time 0.1795802116394043, batch time 0.03667330741882324, forward time 0.04459214210510254, backward time 0.09831380844116211
[2025-04-18 13:59:48,979][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 26/97: loss 2.155667543411255, total_time 0.1774582862854004, batch time 0.03595447540283203, forward time 0.048303842544555664, backward time 0.09319925308227539
[2025-04-18 13:59:49,153][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 35/97: loss 3.041137456893921, total_time 0.1795215606689453, batch time 0.03564023971557617, forward time 0.04524350166320801, backward time 0.09863686561584473
[2025-04-18 13:59:49,159][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 27/97: loss 4.594465255737305, total_time 0.17966699600219727, batch time 0.035521745681762695, forward time 0.05045127868652344, backward time 0.09369301795959473
[2025-04-18 13:59:49,331][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 36/97: loss 3.0373449325561523, total_time 0.17755842208862305, batch time 0.03474116325378418, forward time 0.04467892646789551, backward time 0.09813761711120605
[2025-04-18 13:59:49,337][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 28/97: loss 3.184281587600708, total_time 0.17735791206359863, batch time 0.035045623779296875, forward time 0.049367427825927734, backward time 0.09294390678405762
[2025-04-18 13:59:49,511][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 37/97: loss 3.2303240299224854, total_time 0.18001270294189453, batch time 0.03702116012573242, forward time 0.044734954833984375, backward time 0.09825563430786133
[2025-04-18 13:59:49,517][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 29/97: loss 3.1265687942504883, total_time 0.18036794662475586, batch time 0.03690648078918457, forward time 0.05000948905944824, backward time 0.09345078468322754
[2025-04-18 13:59:49,687][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 38/97: loss 1.931959867477417, total_time 0.1750802993774414, batch time 0.03497505187988281, forward time 0.042029619216918945, backward time 0.09807467460632324
[2025-04-18 13:59:49,695][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 30/97: loss 2.9458861351013184, total_time 0.17639470100402832, batch time 0.036871910095214844, forward time 0.0489194393157959, backward time 0.09060239791870117
[2025-04-18 13:59:49,863][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 39/97: loss 1.8092842102050781, total_time 0.17539358139038086, batch time 0.035149335861206055, forward time 0.04195690155029297, backward time 0.09828639030456543
[2025-04-18 13:59:49,871][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 31/97: loss 3.9058334827423096, total_time 0.1753699779510498, batch time 0.03491783142089844, forward time 0.0496220588684082, backward time 0.09082913398742676
[2025-04-18 13:59:50,042][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 40/97: loss 1.8312954902648926, total_time 0.17851495742797852, batch time 0.03481888771057129, forward time 0.04522371292114258, backward time 0.09847164154052734
[2025-04-18 13:59:50,048][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 32/97: loss 2.1517720222473145, total_time 0.176527738571167, batch time 0.034845590591430664, forward time 0.048143625259399414, backward time 0.09353780746459961
[2025-04-18 13:59:50,224][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 41/97: loss 1.7283798456192017, total_time 0.18223905563354492, batch time 0.036468505859375, forward time 0.047666072845458984, backward time 0.09810352325439453
[2025-04-18 13:59:50,228][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 33/97: loss 4.847530364990234, total_time 0.1800858974456787, batch time 0.0352017879486084, forward time 0.04922199249267578, backward time 0.09566164016723633
[2025-04-18 13:59:50,405][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 42/97: loss 2.1517562866210938, total_time 0.1801297664642334, batch time 0.034952640533447266, forward time 0.047132015228271484, backward time 0.09804415702819824
[2025-04-18 13:59:50,409][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 34/97: loss 1.5846823453903198, total_time 0.18013548851013184, batch time 0.035149574279785156, forward time 0.04940533638000488, backward time 0.09557986259460449
[2025-04-18 13:59:50,586][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 43/97: loss 3.20204496383667, total_time 0.1806626319885254, batch time 0.03504014015197754, forward time 0.047712087631225586, backward time 0.09790921211242676
[2025-04-18 13:59:50,590][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 35/97: loss 3.274738311767578, total_time 0.1807396411895752, batch time 0.03506040573120117, forward time 0.0502016544342041, backward time 0.09547710418701172
[2025-04-18 13:59:50,766][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 44/97: loss 1.6645317077636719, total_time 0.18003106117248535, batch time 0.03472590446472168, forward time 0.04713249206542969, backward time 0.09817171096801758
[2025-04-18 13:59:50,770][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 36/97: loss 3.5069618225097656, total_time 0.18012499809265137, batch time 0.0350489616394043, forward time 0.04934978485107422, backward time 0.09572529792785645
[2025-04-18 13:59:50,948][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 45/97: loss 2.9210097789764404, total_time 0.18129944801330566, batch time 0.03562641143798828, forward time 0.04737281799316406, backward time 0.09829878807067871
[2025-04-18 13:59:50,952][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 37/97: loss 3.196251392364502, total_time 0.18112397193908691, batch time 0.03528165817260742, forward time 0.05008053779602051, backward time 0.09576034545898438
[2025-04-18 13:59:51,129][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 46/97: loss 1.6415042877197266, total_time 0.17996549606323242, batch time 0.03474140167236328, forward time 0.04712986946105957, backward time 0.09809327125549316
[2025-04-18 13:59:51,133][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 38/97: loss 3.2912747859954834, total_time 0.18008708953857422, batch time 0.03570055961608887, forward time 0.048863887786865234, backward time 0.09552192687988281
[2025-04-18 13:59:51,309][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 47/97: loss 2.704552173614502, total_time 0.18013978004455566, batch time 0.034661293029785156, forward time 0.04723548889160156, backward time 0.09824228286743164
[2025-04-18 13:59:51,313][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 39/97: loss 2.1445560455322266, total_time 0.18030595779418945, batch time 0.03563952445983887, forward time 0.04879260063171387, backward time 0.09587311744689941
[2025-04-18 13:59:51,490][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 48/97: loss 2.260754346847534, total_time 0.1800065040588379, batch time 0.03464365005493164, forward time 0.04710721969604492, backward time 0.09825491905212402
[2025-04-18 13:59:51,494][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 40/97: loss 3.2032103538513184, total_time 0.1798872947692871, batch time 0.03519272804260254, forward time 0.0489659309387207, backward time 0.09572768211364746
[2025-04-18 13:59:51,675][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 49/97: loss 3.496807098388672, total_time 0.1842970848083496, batch time 0.03627896308898926, forward time 0.04942011833190918, backward time 0.09859704971313477
[2025-04-18 13:59:51,677][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 41/97: loss 2.1906046867370605, total_time 0.18251395225524902, batch time 0.03494119644165039, forward time 0.0487971305847168, backward time 0.09877490997314453
[2025-04-18 13:59:51,860][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 50/97: loss 2.1579020023345947, total_time 0.18506693840026855, batch time 0.03667402267456055, forward time 0.050112009048461914, backward time 0.09828019142150879
[2025-04-18 13:59:51,862][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 42/97: loss 1.7508043050765991, total_time 0.18507647514343262, batch time 0.03530764579772949, forward time 0.05116438865661621, backward time 0.0986032485961914
[2025-04-18 13:59:52,043][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 51/97: loss 1.7576909065246582, total_time 0.18292546272277832, batch time 0.03511476516723633, forward time 0.049626827239990234, backward time 0.09818267822265625
[2025-04-18 13:59:52,045][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 43/97: loss 2.2284889221191406, total_time 0.1827235221862793, batch time 0.03665018081665039, forward time 0.04786944389343262, backward time 0.09820342063903809
[2025-04-18 13:59:52,226][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 52/97: loss 1.714144229888916, total_time 0.18212556838989258, batch time 0.034880638122558594, forward time 0.04912376403808594, backward time 0.09812021255493164
[2025-04-18 13:59:52,228][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 44/97: loss 3.06255841255188, total_time 0.18209218978881836, batch time 0.03511381149291992, forward time 0.04895329475402832, backward time 0.09802436828613281
[2025-04-18 13:59:52,410][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 53/97: loss 2.6565403938293457, total_time 0.18301939964294434, batch time 0.03492093086242676, forward time 0.049710750579833984, backward time 0.09838652610778809
[2025-04-18 13:59:52,411][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 45/97: loss 2.2093868255615234, total_time 0.18313813209533691, batch time 0.03484344482421875, forward time 0.0499262809753418, backward time 0.09836769104003906
[2025-04-18 13:59:52,592][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 54/97: loss 2.7953414916992188, total_time 0.18173718452453613, batch time 0.0347137451171875, forward time 0.04906201362609863, backward time 0.0979604721069336
[2025-04-18 13:59:52,594][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 46/97: loss 2.546828269958496, total_time 0.18161392211914062, batch time 0.03509974479675293, forward time 0.048555850982666016, backward time 0.09795784950256348
[2025-04-18 13:59:52,774][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 55/97: loss 3.0873866081237793, total_time 0.1820971965789795, batch time 0.03449368476867676, forward time 0.04933881759643555, backward time 0.09826397895812988
[2025-04-18 13:59:52,776][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 47/97: loss 2.468801975250244, total_time 0.1820211410522461, batch time 0.03539586067199707, forward time 0.04848790168762207, backward time 0.09813642501831055
[2025-04-18 13:59:52,957][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 56/97: loss 2.2017064094543457, total_time 0.18236184120178223, batch time 0.03497004508972168, forward time 0.04911303520202637, backward time 0.09827804565429688
[2025-04-18 13:59:52,959][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 48/97: loss 3.2109103202819824, total_time 0.1824798583984375, batch time 0.03531765937805176, forward time 0.048944711685180664, backward time 0.09821629524230957
[2025-04-18 13:59:53,140][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 57/97: loss 3.4348912239074707, total_time 0.18239068984985352, batch time 0.034787654876708984, forward time 0.049387454986572266, backward time 0.09821462631225586
[2025-04-18 13:59:53,142][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 49/97: loss 5.287598133087158, total_time 0.18242835998535156, batch time 0.03540325164794922, forward time 0.04868006706237793, backward time 0.09834432601928711
[2025-04-18 13:59:53,323][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 58/97: loss 4.138364791870117, total_time 0.1826794147491455, batch time 0.034757137298583984, forward time 0.04964876174926758, backward time 0.09827303886413574
[2025-04-18 13:59:53,325][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 50/97: loss 3.4678664207458496, total_time 0.18268752098083496, batch time 0.035597801208496094, forward time 0.048790931701660156, backward time 0.0982978343963623
[2025-04-18 13:59:53,507][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 59/97: loss 2.75797438621521, total_time 0.18327665328979492, batch time 0.03595447540283203, forward time 0.04898476600646973, backward time 0.09833645820617676
[2025-04-18 13:59:53,509][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 51/97: loss 2.573230266571045, total_time 0.18323230743408203, batch time 0.035344600677490234, forward time 0.04952263832092285, backward time 0.09836459159851074
[2025-04-18 13:59:53,690][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 60/97: loss 1.9171745777130127, total_time 0.18271827697753906, batch time 0.03492236137390137, forward time 0.049284934997558594, backward time 0.0985100269317627
[2025-04-18 13:59:53,692][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 52/97: loss 1.2549207210540771, total_time 0.18270087242126465, batch time 0.03522300720214844, forward time 0.04896354675292969, backward time 0.09851384162902832
[2025-04-18 13:59:53,876][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 53/97: loss 1.8726695775985718, total_time 0.1835927963256836, batch time 0.03529548645019531, forward time 0.04923391342163086, backward time 0.09906268119812012
[2025-04-18 13:59:53,877][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 61/97: loss 5.1620893478393555, total_time 0.18673062324523926, batch time 0.03909158706665039, forward time 0.04912972450256348, backward time 0.09850835800170898
[2025-04-18 13:59:54,061][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 62/97: loss 2.865034580230713, total_time 0.18304991722106934, batch time 0.035552024841308594, forward time 0.04897594451904297, backward time 0.09852123260498047
[2025-04-18 13:59:54,063][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 54/97: loss 2.856088638305664, total_time 0.18632125854492188, batch time 0.036920785903930664, forward time 0.050843000411987305, backward time 0.0985565185546875
[2025-04-18 13:59:54,244][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 63/97: loss 2.4269909858703613, total_time 0.18280339241027832, batch time 0.03485298156738281, forward time 0.04974532127380371, backward time 0.09820437431335449
[2025-04-18 13:59:54,246][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 55/97: loss 2.1909871101379395, total_time 0.1826322078704834, batch time 0.03538703918457031, forward time 0.04909801483154297, backward time 0.09814667701721191
[2025-04-18 13:59:54,428][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 64/97: loss 3.159651279449463, total_time 0.18332815170288086, batch time 0.03644967079162598, forward time 0.04892992973327637, backward time 0.09794783592224121
[2025-04-18 13:59:54,430][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 56/97: loss 3.5223195552825928, total_time 0.18332743644714355, batch time 0.03542137145996094, forward time 0.05001354217529297, backward time 0.09789204597473145
[2025-04-18 13:59:54,611][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 65/97: loss 1.7054564952850342, total_time 0.18289852142333984, batch time 0.034677743911743164, forward time 0.04972338676452637, backward time 0.09849667549133301
[2025-04-18 13:59:54,613][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 57/97: loss 1.9054663181304932, total_time 0.18328285217285156, batch time 0.03519940376281738, forward time 0.04935431480407715, backward time 0.09872865676879883
[2025-04-18 13:59:54,799][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 58/97: loss 1.9522905349731445, total_time 0.1856389045715332, batch time 0.037453413009643555, forward time 0.04999089241027832, backward time 0.09819364547729492
[2025-04-18 13:59:54,801][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 66/97: loss 2.1670784950256348, total_time 0.18926477432250977, batch time 0.04087424278259277, forward time 0.05016279220581055, backward time 0.09822678565979004
[2025-04-18 13:59:54,985][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 59/97: loss 2.793945789337158, total_time 0.18551874160766602, batch time 0.03776836395263672, forward time 0.04908943176269531, backward time 0.09865999221801758
[2025-04-18 13:59:54,987][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 67/97: loss 2.066784143447876, total_time 0.18542766571044922, batch time 0.03683781623840332, forward time 0.050467729568481445, backward time 0.09812092781066895
[2025-04-18 13:59:55,169][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 60/97: loss 1.6262036561965942, total_time 0.1835634708404541, batch time 0.03569626808166504, forward time 0.0492701530456543, backward time 0.09859657287597656
[2025-04-18 13:59:55,171][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 68/97: loss 2.323549509048462, total_time 0.18352127075195312, batch time 0.0351102352142334, forward time 0.050390005111694336, backward time 0.09801983833312988
[2025-04-18 13:59:55,353][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 61/97: loss 2.3630332946777344, total_time 0.18282651901245117, batch time 0.035166025161743164, forward time 0.04906582832336426, backward time 0.09859395027160645
[2025-04-18 13:59:55,354][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 69/97: loss 2.637759208679199, total_time 0.1829833984375, batch time 0.03498983383178711, forward time 0.049790143966674805, backward time 0.09820246696472168
[2025-04-18 13:59:55,537][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 70/97: loss 2.040217399597168, total_time 0.18266725540161133, batch time 0.03491830825805664, forward time 0.04947662353515625, backward time 0.09827160835266113
[2025-04-18 13:59:55,539][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 62/97: loss 2.639920711517334, total_time 0.18621039390563965, batch time 0.038492441177368164, forward time 0.04912376403808594, backward time 0.09859371185302734
[2025-04-18 13:59:55,721][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 71/97: loss 1.9162333011627197, total_time 0.18278002738952637, batch time 0.03485870361328125, forward time 0.049546241760253906, backward time 0.0983741283416748
[2025-04-18 13:59:55,723][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 63/97: loss 2.671945571899414, total_time 0.18282389640808105, batch time 0.035223960876464844, forward time 0.048847198486328125, backward time 0.09875202178955078
[2025-04-18 13:59:55,903][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 72/97: loss 1.7997705936431885, total_time 0.18248820304870605, batch time 0.03484082221984863, forward time 0.049427032470703125, backward time 0.09821939468383789
[2025-04-18 13:59:55,906][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 64/97: loss 1.7905210256576538, total_time 0.1824643611907959, batch time 0.035127878189086914, forward time 0.048789262771606445, backward time 0.09854626655578613
[2025-04-18 13:59:56,087][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 73/97: loss 2.498974084854126, total_time 0.18294692039489746, batch time 0.03503155708312988, forward time 0.04974055290222168, backward time 0.0981740951538086
[2025-04-18 13:59:56,089][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 65/97: loss 2.244530439376831, total_time 0.1828150749206543, batch time 0.035364389419555664, forward time 0.04928445816040039, backward time 0.09816575050354004
[2025-04-18 13:59:56,268][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 74/97: loss 2.565077781677246, total_time 0.18007802963256836, batch time 0.03456854820251465, forward time 0.04703688621520996, backward time 0.09847164154052734
[2025-04-18 13:59:56,272][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 66/97: loss 4.894731521606445, total_time 0.18239068984985352, batch time 0.037166595458984375, forward time 0.048871755599975586, backward time 0.09635138511657715
[2025-04-18 13:59:56,449][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 75/97: loss 2.011704683303833, total_time 0.180556058883667, batch time 0.03488636016845703, forward time 0.047599077224731445, backward time 0.09806942939758301
[2025-04-18 13:59:56,452][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 67/97: loss 1.805086374282837, total_time 0.18021297454833984, batch time 0.03509020805358887, forward time 0.049674272537231445, backward time 0.09544777870178223
[2025-04-18 13:59:56,630][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 76/97: loss 3.213988780975342, total_time 0.1805284023284912, batch time 0.034867048263549805, forward time 0.04753565788269043, backward time 0.09812474250793457
[2025-04-18 13:59:56,633][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 68/97: loss 2.0514395236968994, total_time 0.18058085441589355, batch time 0.03550219535827637, forward time 0.049468040466308594, backward time 0.09560990333557129
[2025-04-18 13:59:56,810][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 77/97: loss 1.4675753116607666, total_time 0.18039917945861816, batch time 0.034811973571777344, forward time 0.047220468521118164, backward time 0.09836602210998535
[2025-04-18 13:59:56,814][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 69/97: loss 3.1536707878112793, total_time 0.18062925338745117, batch time 0.03500032424926758, forward time 0.04958629608154297, backward time 0.09604167938232422
[2025-04-18 13:59:56,992][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 78/97: loss 2.16727352142334, total_time 0.1809837818145752, batch time 0.03475522994995117, forward time 0.04778766632080078, backward time 0.09843993186950684
[2025-04-18 13:59:56,996][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 70/97: loss 2.3371105194091797, total_time 0.18084406852722168, batch time 0.03509783744812012, forward time 0.04981517791748047, backward time 0.09593009948730469
[2025-04-18 13:59:57,176][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 79/97: loss 1.8300257921218872, total_time 0.18378853797912598, batch time 0.03600811958312988, forward time 0.04966330528259277, backward time 0.09811615943908691
[2025-04-18 13:59:57,178][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 71/97: loss 1.7469236850738525, total_time 0.18175268173217773, batch time 0.03551292419433594, forward time 0.04827094078063965, backward time 0.09796786308288574
[2025-04-18 13:59:57,356][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 80/97: loss 1.1293349266052246, total_time 0.1797020435333252, batch time 0.034377098083496094, forward time 0.047064781188964844, backward time 0.09825921058654785
[2025-04-18 13:59:57,360][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 72/97: loss 2.2471203804016113, total_time 0.1817474365234375, batch time 0.0379786491394043, forward time 0.04809069633483887, backward time 0.09567761421203613
[2025-04-18 13:59:57,538][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 81/97: loss 2.3096084594726562, total_time 0.1816542148590088, batch time 0.034763336181640625, forward time 0.0483858585357666, backward time 0.09850406646728516
[2025-04-18 13:59:57,542][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 73/97: loss 1.9608643054962158, total_time 0.18185734748840332, batch time 0.03502678871154785, forward time 0.050629615783691406, backward time 0.09619951248168945
[2025-04-18 13:59:57,717][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 82/97: loss 1.9539825916290283, total_time 0.17794585227966309, batch time 0.03470349311828613, forward time 0.04517483711242676, backward time 0.09806656837463379
[2025-04-18 13:59:57,723][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 74/97: loss 2.2731990814208984, total_time 0.1797480583190918, batch time 0.0366363525390625, forward time 0.05002188682556152, backward time 0.09308886528015137
[2025-04-18 13:59:57,895][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 83/97: loss 2.038663148880005, total_time 0.17770624160766602, batch time 0.03471088409423828, forward time 0.04455256462097168, backward time 0.09844207763671875
[2025-04-18 13:59:57,901][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 75/97: loss 1.5411837100982666, total_time 0.17777252197265625, batch time 0.03501129150390625, forward time 0.049376726150512695, backward time 0.0933840274810791
[2025-04-18 13:59:58,073][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 84/97: loss 1.7927844524383545, total_time 0.1779952049255371, batch time 0.03521370887756348, forward time 0.044415950775146484, backward time 0.09836459159851074
[2025-04-18 13:59:58,079][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 76/97: loss 2.1823220252990723, total_time 0.17801976203918457, batch time 0.03526663780212402, forward time 0.04928088188171387, backward time 0.09347128868103027
[2025-04-18 13:59:58,252][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 85/97: loss 0.7785347700119019, total_time 0.17836475372314453, batch time 0.03499937057495117, forward time 0.04479336738586426, backward time 0.0985710620880127
[2025-04-18 13:59:58,259][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 77/97: loss 2.8945443630218506, total_time 0.1786940097808838, batch time 0.03502821922302246, forward time 0.049825191497802734, backward time 0.09383988380432129
[2025-04-18 13:59:58,436][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 86/97: loss 3.272092819213867, total_time 0.18274855613708496, batch time 0.036592960357666016, forward time 0.04783463478088379, backward time 0.09831976890563965
[2025-04-18 13:59:58,439][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 78/97: loss 2.270066738128662, total_time 0.1804354190826416, batch time 0.03505373001098633, forward time 0.049544334411621094, backward time 0.09583663940429688
[2025-04-18 13:59:58,621][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 87/97: loss 2.2509350776672363, total_time 0.18518972396850586, batch time 0.036867380142211914, forward time 0.04970526695251465, backward time 0.09861588478088379
[2025-04-18 13:59:58,623][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 79/97: loss 1.9098809957504272, total_time 0.1834728717803955, batch time 0.034894466400146484, forward time 0.04970383644104004, backward time 0.09887385368347168
[2025-04-18 13:59:58,804][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 88/97: loss 1.897775650024414, total_time 0.1820507049560547, batch time 0.03473162651062012, forward time 0.04921841621398926, backward time 0.0980997085571289
[2025-04-18 13:59:58,806][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 80/97: loss 2.4142274856567383, total_time 0.1816561222076416, batch time 0.03509664535522461, forward time 0.048456668853759766, backward time 0.09810185432434082
[2025-04-18 13:59:58,989][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 81/97: loss 3.117424964904785, total_time 0.18294668197631836, batch time 0.03537917137145996, forward time 0.0490567684173584, backward time 0.0985100269317627
[2025-04-18 13:59:58,990][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 89/97: loss 1.566650152206421, total_time 0.18618202209472656, batch time 0.03667092323303223, forward time 0.05130815505981445, backward time 0.09820199012756348
[2025-04-18 13:59:59,174][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 90/97: loss 3.1366677284240723, total_time 0.18288373947143555, batch time 0.03561067581176758, forward time 0.049069881439208984, backward time 0.09820175170898438
[2025-04-18 13:59:59,176][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 82/97: loss 3.547339916229248, total_time 0.18633008003234863, batch time 0.03659224510192871, forward time 0.051407814025878906, backward time 0.09832930564880371
[2025-04-18 13:59:59,357][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 91/97: loss 2.1343722343444824, total_time 0.18291616439819336, batch time 0.03480029106140137, forward time 0.04983878135681152, backward time 0.09827613830566406
[2025-04-18 13:59:59,359][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 83/97: loss 1.9140150547027588, total_time 0.1830003261566162, batch time 0.034772396087646484, forward time 0.049863338470458984, backward time 0.09836387634277344
[2025-04-18 13:59:59,539][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 92/97: loss 2.3584213256835938, total_time 0.18099331855773926, batch time 0.0350489616394043, forward time 0.04727053642272949, backward time 0.09867262840270996
[2025-04-18 13:59:59,543][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 84/97: loss 1.5786361694335938, total_time 0.18314409255981445, batch time 0.036516427993774414, forward time 0.05023789405822754, backward time 0.0963890552520752
[2025-04-18 13:59:59,720][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 93/97: loss 1.9985169172286987, total_time 0.18058991432189941, batch time 0.03476667404174805, forward time 0.04776191711425781, backward time 0.09806060791015625
[2025-04-18 13:59:59,724][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 85/97: loss 3.962477922439575, total_time 0.18033742904663086, batch time 0.036635637283325195, forward time 0.04818606376647949, backward time 0.09551501274108887
[2025-04-18 13:59:59,902][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 94/97: loss 1.8383350372314453, total_time 0.18189501762390137, batch time 0.03567910194396973, forward time 0.04819917678833008, backward time 0.09801602363586426
[2025-04-18 13:59:59,906][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 86/97: loss 2.2571749687194824, total_time 0.18173837661743164, batch time 0.03571772575378418, forward time 0.05061912536621094, backward time 0.09540057182312012
[2025-04-18 14:00:00,081][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 95/97: loss 1.6994258165359497, total_time 0.17838072776794434, batch time 0.03480172157287598, forward time 0.04530763626098633, backward time 0.09827065467834473
[2025-04-18 14:00:00,087][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 87/97: loss 2.482574462890625, total_time 0.17984509468078613, batch time 0.038114070892333984, forward time 0.048470497131347656, backward time 0.09325981140136719
[2025-04-18 14:00:00,259][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 96/97: loss 1.3003814220428467, total_time 0.17766809463500977, batch time 0.03500199317932129, forward time 0.04457497596740723, backward time 0.09809041023254395
[2025-04-18 14:00:00,265][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 88/97: loss 2.066831111907959, total_time 0.17760896682739258, batch time 0.03471016883850098, forward time 0.04969477653503418, backward time 0.09320330619812012
[2025-04-18 14:00:00,437][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 97/97: loss 1.9508628845214844, total_time 0.17749571800231934, batch time 0.034700632095336914, forward time 0.04469561576843262, backward time 0.0980982780456543
[2025-04-18 14:00:00,438][the_well.benchmark.trainer.training][INFO] - Epoch 1/4: avg training loss 2.94988403983952
[2025-04-18 14:00:00,443][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 89/97: loss 3.0332164764404297, total_time 0.17754316329956055, batch time 0.03528714179992676, forward time 0.049115896224975586, backward time 0.0931391716003418
[2025-04-18 14:00:00,486][the_well.benchmark.trainer.training][INFO] - Epoch 1/4: starting validation
[2025-04-18 14:00:00,551][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 90/97: loss 1.6613273620605469, total_time 0.10733985900878906, batch time 0.03643465042114258, forward time 0.02485203742980957, backward time 0.04605269432067871
[2025-04-18 14:00:00,666][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 91/97: loss 1.1118873357772827, total_time 0.11372089385986328, batch time 0.03528761863708496, forward time 0.026036977767944336, backward time 0.05239558219909668
[2025-04-18 14:00:00,772][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 92/97: loss 1.8721644878387451, total_time 0.10599279403686523, batch time 0.03498697280883789, forward time 0.024874448776245117, backward time 0.04613089561462402
[2025-04-18 14:00:00,878][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 93/97: loss 1.791932225227356, total_time 0.10586380958557129, batch time 0.03486824035644531, forward time 0.024863243103027344, backward time 0.04613184928894043
[2025-04-18 14:00:00,986][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 94/97: loss 1.6922330856323242, total_time 0.10756468772888184, batch time 0.03604912757873535, forward time 0.02538013458251953, backward time 0.04613471031188965
[2025-04-18 14:00:01,093][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 95/97: loss 2.349334716796875, total_time 0.10645222663879395, batch time 0.035398006439208984, forward time 0.02494359016418457, backward time 0.04610943794250488
[2025-04-18 14:00:01,201][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 96/97: loss 2.2538795471191406, total_time 0.10695123672485352, batch time 0.03500032424926758, forward time 0.02481555938720703, backward time 0.0471348762512207
[2025-04-18 14:00:01,315][the_well.benchmark.trainer.training][INFO] - Epoch 1, Batch 97/97: loss 2.562701463699341, total_time 0.11379122734069824, batch time 0.03490781784057617, forward time 0.028142690658569336, backward time 0.05074024200439453
[2025-04-18 14:00:01,316][the_well.benchmark.trainer.training][INFO] - Epoch 1/4: avg training loss 3.598298925714396
[2025-04-18 14:00:01,355][the_well.benchmark.trainer.training][INFO] - Epoch 1/4: starting validation
[1;34mwandb[0m: 
[1;34mwandb[0m: 🚀 View run [33mturbulent_radiative_layer_2D-sinenet-SineNet-0.0002[0m at: [34mhttps://wandb.ai/kato-schmidt-university-of-amsterdam/the_well_sinenet_test/runs/hasat67q[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: 🚀 View run [33mturbulent_radiative_layer_2D-sinenet-SineNet-0.0002[0m at: [34mhttps://wandb.ai/kato-schmidt-university-of-amsterdam/the_well_sinenet_test/runs/hasat67q[0m

JOB STATISTICS
==============
Job ID: 11261696
Cluster: snellius
User/Group: kschmidt/kschmidt
State: FAILED (exit code 143)
Nodes: 1
Cores per node: 16
CPU Utilized: 00:01:53
CPU Efficiency: 17.23% of 00:10:56 core-walltime
Job Wall-clock time: 00:00:41
Memory Utilized: 2.37 GB
Memory Efficiency: 1.32% of 180.00 GB (180.00 GB/node)
The task which had the largest memory consumption differs by 101.50% from the average task max memory consumption
